{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "### Purpose\n",
    "Purpose of the notebook is to demonstrate mathematical intuition behind SVM. The intent is to first work out the underlying maths by hand\n",
    "and then replicate it via python libraries. This will help to crystalise the understanding of anyone\n",
    "who is using packages to solve these problems.\n",
    "\n",
    "### Structure\n",
    "The notebook is structured in 3 different sections:\n",
    "1. [Mathemactical theory](#section_2)\n",
    "2. [Workout example by hand](#section_3)\n",
    "3. [Use sklearn package to replicate](#section_4)\n",
    "\n",
    "### Who is this post for:\n",
    "If you want to bridge the gap between the mathematical theory and what is available via open source packages, then this notebook will help you.\n",
    "\n",
    "If you get confused by what the various attributes of sklearn svm.SVC such as dual_coef_ and coef_, then this post will help you.\n",
    "\n",
    "Post does not assume a lot of mathematical knowledge. In an attempt to explain from first principles, notebook has ended up a little heavy on maths. This shouldn't deter the reader as it comes with the added advantage of explaining all derivations.\n",
    "\n",
    "Highly recommend to watch the lecture from late Prof. Patrick Winston listed below and the MIT recitation video below, before reviewing the notebbok. Reviewing the notebook later after watching those videos, will help to connect it back to what is available in sklearn to put everything into practice.\n",
    "### Reference:\n",
    "* Credits to section 2 - [Lecture by Patrick Winston MIT](https://www.youtube.com/watch?v=_PwhiWxHK8o)\n",
    "* Credits to section 3 - [MIT Recitation on SVM](https://www.youtube.com/watch?v=ik7E7r2a1h8).\n",
    "* Many thanks to https://github.com/jazzapple for reviewing the notebook and providing feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition\n",
    "\n",
    "Consider 2 clusters of points as illustrated below. It is possible to draw many lines to separate out the two set of points. Which line will best separate the 2 categories in unseen data points?\n",
    "<img src=\"./img/0_many_lines.png\" width=\"400\">\n",
    "\n",
    "For the best separating line, consider the margin possible for each of the lines. The one with the maximum margin is the one that separates best. In the diagram below, middle line has the maximum margin. Hence, it separates the 2 set of points better.\n",
    "<img src=\"./img/0_many_lines_margin.png\" width=\"400\">\n",
    "\n",
    "With this intuition, let us try to formalize how to determine the the line with the maximum margin. Extending the problem to n dimensions, question becomes how to determine the hyperplane with maximum margin.\n",
    "\n",
    "Borrowing terminology from Prof. Patrick Winston, separating hyperplane can be considered as street. We are trying to maximise the width of the street (the green shaded area above). Street is framed by gutters lying at ends of the street. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mathematical Background \n",
    "<a id='section_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Derive decision rule \n",
    "\n",
    "We are using geometrical intuition to derive the decision boundary. \n",
    "\n",
    "The figure shows the hyperplane separating positive and negative points. \n",
    "$\\vec{w}$ is the perpendicular vector to the separating hyperplane with maximum margin\n",
    "$\\vec{u}$ is the unknown vector. \n",
    "\n",
    "Thinking about it geometricallly in 2 dimension, to find if the unknown vector($\\vec{u}$), lies on the either side of the hyperplane, we need to project the unknown vector($\\vec{u}$) along the direction of w. If the projection of the unknown vector($\\vec{u}$) along w, lies on the right side of the hyperplane, then it is a positive example. If the projection of the unknown vector($\\vec{u}$) along w lies on the left side of the hyperplace, then it is a negative example. \n",
    "\n",
    "Translating the above geometric intuition to linear algebra, Find the dot product between $\\vec{u}$ and $\\vec{w}$. If the distance is greater than a constant c, it lies on the positive side of the hyperplane. It is less than constant c, it lies on negative side of the hyperplane.\n",
    "\n",
    "$\\vec{w}.\\vec{u} >= c$\n",
    "\n",
    "$\\vec{w}.\\vec{u} -c >=0$\n",
    "\n",
    "$\\vec{w}.\\vec{u} -c >0$ Then positive class else negative class\n",
    "\n",
    "<img src=\"./img/1_hyperplane.png\" width=\"500\">\n",
    "\n",
    "For mathematical convenience, we will denote positive classes denoted by +1 and negative classes by -1.\n",
    "Substituting -c = b,\n",
    "\n",
    "$\\vec{w}.\\vec{u} +b >=0 \\textrm{ then } +1 \\textrm { else } -1$\n",
    "\n",
    "Thus, we have arrived at our decision rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![01_eq_decision_boundary.png](./img/01_eq_decision_boundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Derive width of the hyperplane\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/2_width_hyperplane.png\" width=\"500\">\n",
    "\n",
    "Using the decision rule and modifying it to introduce the constraint. Let us denote positive sample by $\\vec{x_+}$ and negative sample by $\\vec{x_-}$\n",
    "\n",
    "We are denoting y for positive classes as +1 and y for negative classes as -1. \n",
    "\n",
    "Decision rule for positive class becomes $\\vec{w}\\vec{x_+} + b >=1$ \n",
    "\n",
    "Decision rule for negative class becomes $ \\vec{w}\\vec{x_-} + b <= -1$\n",
    "\n",
    "Let us introduce a new variable $y_i = +1$ for positive samples. $y_i = -1$ for negative samples.\n",
    "\n",
    "$y_i(\\vec{w}.\\vec{x_i} + b) -1 >=0$\n",
    "\n",
    "For support vectors, $$y_i(\\vec{w}\\vec{x_i} + b) - 1 =0$$\n",
    "Substituting for positive classes $y_+ = 1$\n",
    "$$\\vec{w}\\vec{x_+} = 1 - b$$\n",
    "\n",
    "Substituting for negative classes $y_- = 1$\n",
    "$$-1(\\vec{w}\\vec{x_- +b} = 1 $$\n",
    "$$\\vec{w}\\vec{x_-} = -1 - b$$\n",
    "\n",
    "Let us denote 2 points $x_+$ and $x_-$ on the gutters. Straight distance d can be obtained by multiplying $x_+$ and $x_-$ with unit vector. \n",
    "\n",
    "w is normal to decision boundary.\n",
    "\n",
    "$\\frac{\\vec{w}}{\\lVert w \\rVert}$ is the unit vector.\n",
    "\n",
    "width $d = (x_+ - x_-)\\frac{\\vec{w}}{\\lVert w \\rVert}$\n",
    "\n",
    "$d = \\frac{x_+\\vec{w} - x_-\\vec{w}}{\\lVert w \\rVert}$\n",
    "\n",
    "$d = \\frac{1 - b + 1 + b}{\\lVert w \\rVert}$\n",
    "\n",
    "$d = \\frac{2}{\\lVert w \\rVert}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![02_eq_width_hyperplane.png](./img/02_eq_width_hyperplane.png)\n",
    "\n",
    "**Note : It is very easy to confuse margin width with $\\lVert w \\rVert$. Key thing to note is $\\lVert w \\rVert$ is  inversely proportional to margin width. When magnitude of $\\vec{w}$ increases, margin width decreases.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Formalize objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to maximize the width of the hyperplane identified in Step 2 -  $\\frac{2}{\\lVert w \\rVert}$ subject to\n",
    "the constraint identified in Step 1 -  $\\vec{w}\\vec{x} + b > 0$\n",
    "\n",
    "Maximise $\\frac{2}{\\lVert w \\rVert}$ such that $\\vec{w}\\vec{x} + b > 0$ \n",
    "\n",
    "Maximising $\\frac{2}{\\lVert w \\rVert}$ is same as minimising ${\\lVert w \\rVert}^2$\n",
    "\n",
    "So, the objective function becomes minimise ${\\lVert w \\rVert}^2$ such that $\\vec{w}\\vec{x} + b > 0$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Optimise\n",
    "\n",
    "A technique from math called [Lagrangian Multiplier](https://en.wikipedia.org/wiki/Lagrange_multiplier) is used to solve the above objective.\n",
    "\n",
    "The method can be summarized as follows: in order to find the maximum or minimum of a function $f(x)$ subjected to the equality constraint $g(x)=0$, form the Lagrangian function\n",
    "\n",
    "${L}(x,\\lambda )=f(x)-\\lambda g(x)$\n",
    "\n",
    "$f(x) = {\\frac{1}{2}}{\\lVert}w{\\rVert}^2 $\n",
    "\n",
    "$g(x) = y_i(\\vec{w}\\vec{x_i}+b) -1 = 0$\n",
    "\n",
    "Using the lagrangian multiplier $\\alpha$ leads to defining the **Primal problem** \n",
    "\n",
    "$$ L = {\\frac{1}{2}}{\\lVert}w{\\rVert}^2 - \\sum \\alpha_i{\\lbrack}y_i(\\vec{w}\\vec{x_i}+b) -1{\\rbrack}$$\n",
    "\n",
    "To find extremum of function, calculate derivate w.r.t moving parts and set them to 0\n",
    "$$ L = {\\frac{1}{2}}{\\lVert}w{\\rVert}^2 - \\sum \\alpha_i y_i \\vec{w}\\vec{x_i} - \\sum \\alpha_i y_i b + \\sum \\alpha_i$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w} = 0$\n",
    "\n",
    "Calculating the derivatives of each of the components in the equation above:\n",
    "$$\\frac{\\partial {\\lVert}w{\\rVert}^2}{\\partial w} = \\vec{w} $$\n",
    "\n",
    "$$\\frac{\\partial {\\alpha_i y_i \\vec{w}\\vec{x_i}}}{\\partial w} = \\alpha_i y_i \\vec{x_i} $$\n",
    "\n",
    "No w term, derivative w.r.t constant $\\frac{\\alpha_i y_i b}{\\partial w} = 0 $\n",
    "\n",
    "No w term, derivative w.r.t constant $\\frac{\\alpha_i}{\\partial w} = 0 $ \n",
    "\n",
    "$$\\vec{w} - \\sum {\\alpha_i} y_i \\vec{x_i} = 0 $$\n",
    "$$\\vec{w} = \\sum {\\alpha_i} y_i \\vec{x_i} $$\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b} = 0$\n",
    "$$\\sum \\alpha_i y_i = 0 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the dual problem optimisation, because the constraint is an inequalilty, all the [KKT conditions](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions) need to be satisfied.\n",
    "\n",
    "Complementary slackness condition on the inequality constraint leads to the following equation: \n",
    "$ \\alpha_i{\\lbrack}y_i(\\vec{w}\\vec{x_i}+b) -1{\\rbrack} = 0 $\n",
    "\n",
    "Which leads to the intuition behind the non support vectors, when  $y_i(\\vec{w}\\vec{x_i}+b) != 1 => \\alpha_i = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step above provide 3 main equations that are critical:\n",
    "![03_eq_primal_problem.png](./img/03_eq_primal_problem.png)  \n",
    "\n",
    "![04_eq_support_vector_coefficient.png](./img/04_eq_support_vector_coefficient.png)\n",
    "\n",
    "![05_eq_support_vector_sum.png](./img/05_eq_support_vector_sum.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition : \n",
    "\n",
    "##### Intuition on Weights\n",
    "* If a point is not on a support vector, then alpha for that will be 0.\n",
    "$\\vec{w}$ is the linear sum of some training samples. For non support vectors $\\alpha_i$ will be zero. Hence, $w_i$ will be 0 .\n",
    "\n",
    "* Sum of alphas across all the categories will be 0. For binary classification, sum of alphas for positive class is same as the sum of alphas for the negative class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Dual Problem\n",
    "Substituting values back into the primal problem \n",
    "\n",
    "$$ L = {\\frac{1}{2}}{\\lVert}w{\\rVert}^2 - \\sum \\alpha_i{\\lbrack}y_i(\\vec{w}\\vec{x_i}+b) -1{\\rbrack}$$\n",
    "\n",
    "\n",
    "$$ L = {\\frac{1}{2}} \\vec{w}. \\vec{w} - \\sum \\alpha_i{\\lbrack}y_i(\\vec{w}\\vec{x_i}+b) -1{\\rbrack}$$\n",
    "\n",
    "$$  = {\\frac{1}{2}}\\sum_i \\alpha_i y_i \\vec{x_i} \\sum_j \\alpha_j y_j \\vec{x_j} - \\sum_i \\alpha_i y_i\\vec{w}\\vec{x_i} - \\sum \\alpha_i y_i b + \\sum \\alpha_i $$\n",
    "\n",
    "Next, let us substitute the value for $\\vec{w}$ from equation above from primal problem. b is a constant and can be taken out of the summation.\n",
    "\n",
    "$$  = {\\frac{1}{2}}\\sum_i \\alpha_i y_i \\vec{x_i} \\sum_j \\alpha_j y_j \\vec{x_j} - \\sum_i \\alpha_i y_i\\sum_j \\alpha_j y_j \\vec{x_j}\\vec{x_i} - b\\sum \\alpha_i y_i + \\sum \\alpha_i $$\n",
    "\n",
    "From above $ \\sum \\alpha_iy_i = 0 $, so term with constant b is 0.\n",
    "$\\sum \\alpha_i y_i\\sum \\alpha_j y_j \\vec{x_j}\\vec{x_i}$ can be rearranged as $\\sum \\alpha_i y_i \\vec{x_i}\\sum \\alpha_j y_j \\vec{x_j}$\n",
    "\n",
    "$$  = {\\frac{1}{2}}\\sum_i \\alpha_i y_i \\vec{x_i} \\sum_j \\alpha_j y_j \\vec{x_j} - \\sum_i \\alpha_i y_i \\vec{x_i} \\sum_j \\alpha_j y_j \\vec{x_j} - b*0 + \\sum \\alpha_i $$\n",
    "\n",
    "$$ L = \\sum {\\alpha_i} - \\frac{1}{2} \\sum_i \\sum_j {\\alpha_i}{\\alpha_j}{y_i}{y_j}{x_i}{x_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Workout Maths\n",
    "<a id='section_3'></a>\n",
    "In this example, we will take an example of points that are linearly separable.Inspecting the points below, separating hyperplane is from x=1 and x=3. The centre of the separating hyperplane passess through x=2. Width of the separating hyperplane is 2. We will first workout the maths\n",
    "and then try to cross check our results via computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derive decision rule. How to calculate w and b in the decision rule?**\n",
    "\n",
    "***Step 1 : Draw the decision boundary***\n",
    "\n",
    "y=0 are denoted by blue dots. \n",
    "y=1 are denoted by orange crosses\n",
    "\n",
    "Need to draw the street with maximum width that separates the two. \n",
    "A street with width=2 is possible between x=1 and x=3. Middle of the street passes through x=2. \n",
    "\n",
    "<img src=\"./img/03_workout_maths_sample_data.png\" width=\"500\">\n",
    "\n",
    "\n",
    "***Step 2: Write the equation for the boundary $x=2$***\n",
    "This can be written in the standard line equation $1x-0y-2=0$ . Rewiting it this way will help in factorising weights in step3.\n",
    "\n",
    "***Step 3: Rewite the above equation in the form $wx + b = 0$***\n",
    " $$\\begin{bmatrix} ? & ? \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} + b = 0$$\n",
    " \n",
    "Extrapolating from the line equation above, we can fill in the dashes\n",
    "\n",
    "**Equation1**\n",
    " $$\\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} - 2 = 0$$\n",
    " \n",
    "Equation 1 has a degree of freedom. It is possible to multiply it by a constant and still satisfy the equation. So, we need to introduce scaling by a constant such that $\\textrm {margin width}  = \\frac{2}{\\lVert w \\rVert}$. However, that alone won't be sufficient as we need to introduce the constraint that w points to positive class. \n",
    "\n",
    "**Equation2**\n",
    "Scale Equation1 by a constant such that $$\\textrm {margin width} =\\frac{2}{\\lVert w \\rVert}$$. \n",
    "\n",
    "A more easier way mathematically, is to introduce gutter constraint\n",
    "\n",
    " $$\\textrm{for positive classes, }wx + b >=1 $$ \n",
    "\n",
    " $$\\textrm{for negative classes, }wx + b <=-1 $$ \n",
    "\n",
    "$wx+b=1$  for gutters for positive class\n",
    "$wx+b=-1$ for gutters for negative class\n",
    "\n",
    "\n",
    "**Equation 3**\n",
    "for all support vectors, $$\\vec{w}\\vec{x} + b = y_i$$\n",
    "$$y_i = class(i) = +1 or -1$$\n",
    "\n",
    "To derive the value of w and b, manually, let us substitute one of the support vectors into the equation. Let us consider point D - (3,2).\n",
    "$$\\vec{w}\\vec{x_D} + b = -1$$\n",
    "\n",
    "Substituting for point D, and using values from equation 1, check if the equation above holds good.\n",
    "$$\\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix} -2 = -1$$\n",
    "$$ 3 -2 != 1 $$\n",
    "\n",
    "So, we have to scale by constant,c\n",
    "$$c*\\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix} -c*2 = -1$$\n",
    "c = -1\n",
    "\n",
    "$$ weight = \\begin{bmatrix} -1 & 0 \\end{bmatrix}$$\n",
    "$$ b = 2 $$\n",
    "\n",
    "From the diagram, we know that margin width = 2. \n",
    "\n",
    "Let us check what $\\frac{2}{\\lVert w \\rVert}$ is : $2/1 = 2$\n",
    "So, we have sense checked this with equation2.\n",
    "\n",
    "Let us also check the direction of $\\vec{w}$.  $\\vec{w}$ points towards -1, 0. It points towards the positive class as shown in the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, far we have calculated $\\vec{w}$ and b. This has formalised the maximum margin hyperplane. Next, we would like to calculate supportiveness of the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating support vector values**\n",
    "\n",
    "Step 1 : For all non-support vectors, $\\alpha=0$.\n",
    " For support vectors,i.e - points on the gutters, $\\alpha>0$\n",
    " \n",
    "Step 2 : There are 2 equations from introducing lagrange multipier.\n",
    "$$\\sum{\\alpha_i}y_i = 0$$\n",
    "Substituting the value $y_i$ for positive and negative classes, \n",
    "$$\\sum_{positive classes}{\\alpha_p} = \\sum_{negative classes}{\\alpha_n}$$\n",
    "Looking at the support vectors in scenario1, we have equation1:\n",
    "$${\\alpha_A} + {\\alpha_B} = {\\alpha_D}$$\n",
    "\n",
    "Step 3: $$\\vec{w} = \\sum{\\alpha_i}y_ix_i$$\n",
    "Looking at the support vectors in scenario1,\n",
    "$$\\vec{w} = {\\alpha_A}y_Ax_A + {\\alpha_B}y_Bx_B + {\\alpha_D}y_Dx_D  $$\n",
    "Substitue the values of $\\vec{w}$, x and y\n",
    "$$\\begin{bmatrix} -1 & 0 \\end{bmatrix}= {\\alpha_A}\\begin{bmatrix}1\\\\3\\end{bmatrix} +  {\\alpha_B}\\begin{bmatrix}1 \\\\1\\end{bmatrix} - \n",
    "{\\alpha_D}\\begin{bmatrix}3\\\\2\\end{bmatrix}$$\n",
    "\n",
    "Deriving 2 equations from above\n",
    "$$-1 = \\alpha_A + \\alpha_B - 3\\alpha_D  \\textrm{    equation_1}$$ \n",
    "$$0 = 3\\alpha_A + \\alpha_B - 2\\alpha_D  \\textrm{    equation_2}$$\n",
    "\n",
    "Subsitute equation from step 2 ${\\alpha_A} + {\\alpha_B} = {\\alpha_D}$, into the equation_1 above.\n",
    "$$-1 = \\alpha_A + \\alpha_B - 3\\alpha_D $$ \n",
    "$$-1 = \\alpha_D - 3\\alpha_D$$\n",
    "$$\\alpha_D = 1/2$$\n",
    "\n",
    "Simplifying the 2 equations (substract equation_2 from equation_1):\n",
    "\n",
    "$$1 = 2\\alpha_A + \\alpha_D $$ \n",
    "Substitute value for $\\alpha_D = \\frac{1}{2}$ \n",
    "$$\\alpha_A = 1/4$$\n",
    "$$\\alpha_B = 1/4$$\n",
    "$$\\alpha_D = 1/2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using Code\n",
    "### sklearn SVM package\n",
    "<a id='section_4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random points for positive class with x1 < 1\n",
    "X1_pos = random.sample(range(-5,1), 5)\n",
    "X2_pos = random.sample(range(0,5), 5)\n",
    "X_pos = np.column_stack([X1_pos, X2_pos])\n",
    "# Add couple of points with x1=1. These are our special support vectors\n",
    "X_pos = np.vstack([X_pos, [[1,1]], [[1,3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random points for negative class with x1 > 4\n",
    "X1_neg = random.sample(range(4, 12), 6)\n",
    "X2_neg = random.sample(range(0, 7), 6)\n",
    "X_neg = np.column_stack([X1_neg, X2_neg])\n",
    "# Add a point with x=3\n",
    "X_neg = np.vstack([X_neg, [[3,2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate data together\n",
    "X = np.vstack([X_pos, X_neg])\n",
    "y = np.concatenate((np.repeat(1,7), np.repeat(0,7)))\n",
    "df = pd.concat([pd.DataFrame(data = X, columns = ['x1', 'x2']),\n",
    "               pd.Series(y, name ='y')],\n",
    "              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(3, 2, 'D')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApgAAAH9CAYAAAC+4Ay9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU5b3///c9W3a2LARRQUClKlJRSlEroIhGwWiEI2hdvkoFvlqFuqH1aHuUuvw8xdPaao9SFyp4REHQI7iAUhS+tWAVAXFBFpUQkrBmneW+f39ERoIsA9wz9zXJ6/l49GHmnsk9n34ymby5rvuay3IcxxEAAADgEp/XBQAAAKBlIWACAADAVQRMAAAAuIqACQAAAFcRMAEAAOAqAiYAAABcFfC6gIO1dWutbLv1frJSfn6uqqtrvC4jLdCrxNz++GI9PO50r8tIC7ymEkOfEkOfEkevEpPKPvl8ltq3z9nn/WkXMG3badUBU1Kr//9/MOjVgW3eWk+fDgK9Sgx9Sgx9Shy9SowpfWKKHAAAAK4iYAIAAMBVBEwAAAC4Ku2uwQQAAEhXsVhUW7dWKhoNu37uzZt9sm3b1XP6fH5lZeUqN7etLMtK+PsImAAAACmydWulMjOzlZNTfFCBLRGBgE/RqHsB03EcxWJR7dy5TVu3VqpDh6KEv5cpcgAAgBSJRsPKyWnjerhMBsuyFAgE1a5dvsLhhoP6XgImAABACqVDuNydZfkkHdzHHxEwAQAA4CoCJgAAAFxFwAQAAICrCJgAAACt0H33/bvmzJkVv33jjddr5coVrpybgAkAANAKXXhhqd5443VJ0qZN5dq2bZtOPPEkV87N52ACAAC0QqeccqqqqipVXr5Rb7zxus4//wLXzs0IJgAAQCtkWZZKSobq7bff0Pz5b+r88y907dwETAAAgFaqpGSoXnnlZXXsWKyCgkLXzpv0gFlTU6OhQ4fqm2++kST9z//8j4YOHaphw4bpzjvvVDjs/l6cAAAAOLCOHYvVsWOxSkqGuXrepAbMjz/+WKNGjdK6deskSWvXrtWUKVP0wgsvaM6cObJtW9OmTUtmCQAAANgLx3FUVVWpLVuq9bOfDXD13EkNmC+++KLuvfdeFRU1bY4eCoV07733Kjc3V5Zl6bjjjtPGjRuTWQIAuGLH4ve1ecG7XpcBAK559935uuaaURoz5gaFQiFXz53UVeSTJk1qdrtz587q3LmzJGnLli16/vnn9cADDxzUOfPzc12rL10VFuZ5XULaoFeJMalPv1nw+6b/nv0rjytpbtMHi1UnqdfZAz2u5Hum9koy6zVlMvqUuJbSq82bfQoEkje+dzDnPvfcITr33CEJPdbn8x3Uz8CTjymqqKjQ6NGjdemll6pfv34H9b3V1TWy7YPbcL0lKSzMU2XlTq/LSAv0KnEm9SkSiUkyqyZJioSjCoYCRtVlaq/43UsMfUpcS+qVbduKRu2knDsQ8CXt3LZtN/sZ+HzWfgf9Ur6KfM2aNRo5cqQuueQS3XDDDal+egAAACRZSkcwa2pqdN1112n8+PG6+OKLU/nUAAAASJGUjmC+9NJLqqqq0tNPP63S0lKVlpbqv/7rv1JZAgAAAJIsJSOYCxYskCRdc801uuaaa1LxlAAAAPAIe5EDMMpJBT/yuoS0Qa8AHK4335yn556bomg0qhEjRunSS//NlfMSMAEYZfDR7n7Yb0tGr4DWYcnKTZq5cI2qdzQqv02GygZ0V/8Tiw/7vJWVm/Xkk3/WlClTFQyGNHbsterT5zQdc0y3wz43e5EDAAAYasnKTXp27mpV72iUJFXvaNSzc1drycpNh33upUs/UJ8+p6lNm7bKysrSoEHn6N135x/2eSUCJgDDPPrhE3r0wye8LiMt0Cug5Zu5cI3Ce3y2ZThqa+bCNYd97qqqSuXnF8Rv5+cXaPPmzYd9XokpcgCG6dfpNK9LSBv0Cmj5do1cJnr8YNi2Lcuy4rcdx5HPZ+3nOxJHwARglP6EpoTRK6Dly2+Tsdcwmd8m47DPXVTUUR9//K/47S1bqlVQUHjY55WYIgdgmJpwrWrCtV6XkRboFdDylQ3ortAe+4uHAj6VDeh+2Oc+7bSfaNmyf2rr1q1qaGjQu+8uUL9+/Q/7vBIjmAAM89SKqZKk8X3GelyJ+egV0PLtWi2ejFXkhYVF+sUv/q9uummMIpGohg0r1QknnHTY55UImAAAAEbrf2KxK4Fyb4YMOV9Dhpzv+nmZIgcAAICrCJgAAABwFQETAAAAriJgAgAAwFUETAAAALiKgAkAAABXETABAABasdraGl155b+pvHyja+fkczABGIX9tRNHr4CWz4lFVf/Go5KkrHNvVP1bjzV9fd54Wf7Dj3ErV67Qww/fr6+/3nDY59odI5gAjNK/02nssZ0gegW0fPVvPKpY+WeKlX+mmucnxL/eFToP16uvztKvfnWHa3uQ78IIJgCj7NpbOzeU43El5qNXQCsSizT9T5L8QddOO3Hiv7t2rt0xggnAKE+tmBrfYxv7R6+Ali/r3BulPafC/QFlnftLbwpKECOYAIxyztFneV1C2qBXQMtX/9ZjUiza/GAsqvq3/qjsC271pqgEEDABGKVXwQlel5A26BXQiviDTSOZe4ZNQzFFDsAoFbWbVVG72esy0gK9Alq+rPPGy9/pePk7Ha/cKybHv846b7zXpe0XI5gAjDL9s5mSpPF9xnpcifnoFdDyWf5As6nwZE2Lv/TSq66ejxFMAAAAuIqACQAAAFcRMAEAAFLIcRyvSzgoh1IvARMAACBFfD6/YmmyEnyXSCQs/0FuS0nABAAASJGsrFzt3LlNjmN7XcoBOY6jcLhR27ZVKje33UF9L6vIAQAAUiQ3t622bq1URcU3ktydKvf5fLJtd4Or3x9QXl57ZWUd3Ja0BEwAAIAUsSxLHToUJeXchYV5qqzcmZRzHyymyAEAAOAqRjABGIX9tRNHrwCYioAJwCjsr504egXAVEyRAzAK+2snjl4BMBUBE4BRpn82M77HNvaPXgEwFVPkAIxyUffzvS4hbdArAKYiYAIwSre2Xb0uIW3QKwCmYoocgFG+2r5OX21f53UZaYFeATAVAROAUeasmac5a+Z5XUZaoFcATEXABAAAgKsImAAAAHAVARMAAACuImACAADAVQRMAAAAuIqACQAAAFcRMAEAAOAqAiYAAABcxVaRAIzC/tqJo1cATEXABGAU9tdOHL0CYCqmyAEYhf21E0evAJgq6QGzpqZGQ4cO1TfffCNJWrx4sYYNG6YhQ4Zo8uTJyX56AGmG/bUTR68AmCqpU+Qff/yx7r77bq1bt06S1NDQoLvuuktTp05Vp06dNGbMGC1cuFADBgxIZhkA0sio48u8LiFt0CsApkrqCOaLL76oe++9V0VFRZKk5cuXq0uXLjrqqKMUCAQ0bNgwzZvHv74BfK9jTpE65hR5XUZaoFcATJXUEcxJkyY1u71582YVFhbGbxcVFamiouKgzpmfn+tKbemssDDP6xLSBr1KjEl9WvrtcknSaZ1P9riS5jaFmt4u6VViTOqTyehT4uhVYkzpU0pXkdu2Lcuy4rcdx2l2OxHV1TWybcft0tJGYWGeKit3el1GWqBXiTOpT7NWvCFJ6hI6xuNKmouEowqGAvQqAfzuJYY+JY5eJSaVffL5rP0O+qV0FXlxcbEqKyvjtysrK+PT5wAAAGgZUhowe/furbVr12r9+vWKxWJ67bXXdNZZZ6WyBAAAACRZSqfIMzIy9OCDD+qXv/ylGhsbNWDAAJ1/PjtRAAAAtCQpCZgLFiyIf92/f3/NmTMnFU8LAAAAD7CTDwAAAFxFwAQAAICrCJgAAABwFQETAAAArkrpKnIAOBD2104cvQJgKgImAKOwt3bi6BUAUzFFDsAon1St0idVq7wuIy3QKwCmYgQTgFHmb/i7JKlXwQkeV2I+egXAVARMAEYZfdKVXpeQNugVAFMRMAEYJTeU43UJaYNeATAV12ACMMqS8qVaUr7U6zLSAr0CYCoCJgCj/KN8qf5BaEoIvQJgKgImAAAAXEXABAAAgKsImAAAAHAVARMAAACuImACAADAVQRMAAAAuIqACQAAAFcRMAEAAOAqtooEYBT2104cvQJgKgImAKOwv3bi6BUAUzFFDsAo7K+dOHoFwFQETABGYX/txNErAKZiihyAUcb3Get1CWmDXgEwFSOYAAAAcBUBE4BR3t6wUG9vWOh1GWmBXgEwFQETgFFWVH2qFVWfel1GWqBXAExFwAQAAICrCJgAAABwFQETAAAAriJgAgAAwFUETAAAALiKgAkAAABXETABAADgKgImAAAAXMVe5ACMwv7aiaNXAEzFCCYAAABcRcAEYBT2104cvQJgKqbIARhl7fb1XpeQNugVAFMRMAEY5Re9rvK6hLRBrwCYiilyAAAAuIqACcAos9fM1ew1c70uIy3QKwCmYoocgFG4rjBx9AqAqRjBBAAAgKsImAAAAHAVARMAAACuImACAADAVQRMAAAAuIqACQAAAFcRMAEAAOAqTz4Hc/bs2frv//5vSdJZZ52lO+64w4syABgoJ5jtdQlpg14BMFXKA2Z9fb0mTZqkefPmqU2bNho1apQWL16s008/PdWlADAQ+2snjl4BMFXKp8hjsZhs21Z9fb2i0aii0agyMjJSXQYAAACSJOUjmLm5ubr55ptVUlKirKws9e3bV3369En4+/Pzc5NYXXooLMzzuoS0Qa8SY1Kfpi1/RZJ0+ckXe1xJc5tCTW+X9CoxJvXJZPQpcfQqMab0KeUBc/Xq1Xr55Zf1zjvvKC8vT7feequmTJmi0aNHJ/T91dU1sm0nyVWaq7AwT5WVO70uIy3Qq8SZ1KfK7Vub/mtQTZIUCUcVDAWMqsvUXvG7lxj6lDh6lZhU9snns/Y76JfygPnee++pf//+ys/PlySVlZVp2rRpCQdMAC3b5T2He11C2qBXAEyV8mswe/bsqcWLF6uurk6O42jBggXq1atXqssAAABAkqR8BPPMM8/UqlWrVFZWpmAwqF69eun6669PdRkADDVt9UuSGJ1LBL0CYCpPPgfz+uuvJ1QC2KvNdVVel5A26BUAU7GTDwAAAFxFwAQAAICrCJgAAABwFQETAAAAriJgAgAAwFUETAAAALiKgAkAAABXefI5mACwL0XZBV6XkDboFQBTETABGIVdaRJHrwCYiilyAAAAuIqACcAo01a/FN9jG/tHrwCYiilyAEbJCeZ4XULaoFcATEXABGCU0u4lXpeQNugVAFMxRQ4AAABXETABGOXJT57Tk58853UZaYFeATAVU+QAjFIbqfO6hLRBrwCYihFMAAAAuIqACQAAAFcRMAEAAOAqAiYAAABcRcAEAACAqwiYAAAAcBUBEwAAAK7iczABGOWYtl28LiFt0CsApiJgAjAK+2snjl4BMBVT5AAAAHAVAROAUdhfO3H0CoCpmCIHYBSuK0wcvQJgKgImAKMMPnqA1yWkDXoFwFRMkQMAAMBVBEwARnn0wyf06IdPeF1GWqBXAExFwAQAAICrCJgAAABwFQETAAAAriJgAgAAwFUETAAAALiKgAkAAABXETABAADgKgImAAAAXMVWkQCMclLBj7wuIW3QKwCmImACMAr7ayeOXgEwFVPkAAAAcBUBE4BR2F87cfQKgKmYIgdglH6dTvO6hLRBrwCYioAJwCj9CU0Jo1cATMUUOQCj1IRrVROu9bqMtECvAJiKgAnAKE+tmKqnVkz1uoy0QK8AmIqACQAAAFcRMAEAgLEsy/K6BBwCFvkAAACj+HyWbMtSJOaoamu9doZjys0KKmA5ikZsr8tDAgiYAADAGH6/T422oz+88C+t+Ko6frx9XoZ+UXqSftSlvZwYIdN0nkyRL1iwQGVlZSopKdH999/vRQkAAMBAMcvSxD+93yxcStLWnY16+G/L9NnX2xQI+D2qDolKecD8+uuvde+99+rPf/6z5syZo1WrVmnhwoWpLgMAABgmEPTp7//6Vlt2NOzzMU/OXqGo46SwKhyKlE+Rv/XWW7rgggtUXFwsSZo8ebIyMjJSXQYAADBMOCa99cGG/T6menuDahuiygmyTtlkKQ+Y69evVzAY1NixY1VeXq6BAwdq/PjxCX9/fn5uEqtLD4WFeV6XkDboVWJM6lMw2DT1ZVJNkrQp1PR2aVJdpvZKMrMmE9Gn5rbsaFBdQ+SAj4vEbBUe0TYFFaUfU15TKQ+YsVhMS5cu1dSpU5Wdna1x48Zp1qxZKisrS+j7q6trZNutd2i8sDBPlZU7vS4jLdCrxJnUpz4Fp0gyqyZJioSjCoYCRtVlaq/43UsMffohy+9TtyPaatlnm/f5GJ8ltckJ0bu9SOVryuez9jvol/Lx5YKCAvXv318dOnRQZmamBg8erOXLl6e6DACG6t/pNPbYThC9QktjOY5GDD52v4859UcdxRIf86U8YA4aNEjvvfeeduzYoVgspkWLFunEE09MdRkADMX+2omjV2hpbNtRx3ZZunRQj73e3yk/R2Mv6SW14pnMdJHyKfLevXtr9OjRuvzyyxWJRHTGGWfo0ksvTXUZAAy1a2/t8X3GelyJ+egVWiInZmvoGV3105M6acaCz7W+fKdysoK6oH9XnfqjIvlsWzFWkRvPkw9aHz58uIYPH+7FUwMw3DlHn+V1CWmDXqGlcqK2CvNCGndxL8VsR5mZQdmRqKKRmGJeF4eEsJMPAKP0KjjB6xLSBr1CS9a0oNeRT1Lb3AxVVoa9LgkHgQ+RAmCUitrNqqjd9wpSfI9eATAVAROAUaZ/NlPTP5vpdRlpgV4BMBUBEwAAAK4iYAIAAMBVBEwAAAC4ioAJAAAAVxEwAQAA4CoCJgAAAFxFwAQAAICrCJgAAABwFVtFAjAK+2snjl4BMBUBE4BR2F87cfQKgKmYIgdgFPbXThy9AmAqAiYAo7C/duLoFQBTMUUOwCgXdT/f6xLSBr0CYCoCJgCjdGvb1esS0ga9AmAqpsgBGOWr7ev01fZ1XpeRFugVAFMRMAEYZc6aeZqzZp7XZaQFE3tlWZbXJQAwAFPkAIDDYlmS5fcp5liq2FqnLXURtc/LkF+OYlHb6/IAeICACQA4ZJZlyQr49ez/rtLfP/pWMduRJGVlBFQ2sIfO7XuU7GjM4yoBpNoBp8ij0egPjm3fvj0pxQAA0ovj8+nhvy3VOx9+Ew+XklTfGNXzb6zWK4u+kuXnaiygtdnnb/2KFSs0aNAgnXLKKRo/frxqamri911zzTWpqA0AYDCfz9LmbXVatXbLPh8zZ9FXijn7vBtAC7XPgDlp0iT95je/0bvvvqtAIKDRo0crHA5LkhyHdwsAaO18fp/mLl6338fYtqPlX1YpEGAUE2hN9vkb39DQoAEDBig/P1+PPPKIioqKdOedd6ayNgCAwWzHUV3DDy+j2lNtfYTV5UArs8+Aadu2qqur47cfeughffnll/rTn/7EGwUAQH7L0vFd2h/wcd2PbKdYjNXkQGuyz4B57bXX6uKLL9bChQslSVlZWXr88cc1c+ZMff755ykrEABgpkgkpoF9jpTPt+9Bh/y2merYIVu2zaVVQGuyz4BZWlqqZ599VitXrowfO+KIIzRnzhxGMAEkzUXdz2eP7QSZ0KuA5ej2n5+qvWXM7MyA7rm2nwIiXAKtzX4/B7Nbt2567bXXVFFRoV//+tfavHmzJkyYoNNPPz1V9QFoZdhfO3Em9MqOOTr+qHZ67LazNXvhl/roiyoF/D797MdH6NyfdFHA4sPWgdbogB+0/tJLL2nSpEm69NJLtWPHDt14440aMWJEKmoD0Art2lvbhPBkOlN65cRsZfmlUecepxFnH6uMjICcmK1oJCY+Yh1onQ74uRGWZSkUCqm+vl62bTM9DiCpTNxf21Qm9cpxJDtqy+c4apeXqWiEaAm0Zgccwbzooov04x//WLNnz1ZVVZVuueUWvf3223riiSdSUR+AVmbU8WVel5A26BUAUx0wYN5www26+OKLJUk5OTmaPn26Jk+enPTCALROHXOKvC4hbdArAKY64BT5rnC5SzAY1O233560ggC0bp9UrdInVau8LiMt0CsApjrgCCYApNL8DX+XJPUqOMHjSsxHrwCYis1hAQAA4CoCJgAAAFxFwAQAAICrCJgAAABwFQETAAAAriJgAgAAwFUETAAAALiKgAkAAABX8UHrAIzC/tqJo1cATEXABGAU9tdOHL0CYCqmyAEYhf21E0evAJiKEUwARmF/7cTRKwCmImACMMrok670uoS0Qa8AmIqACcAouaEcr0tIG/QqMZYlSZYcx/G6FKDV4BrM3fj9ljrk+ZXhd/Z7DEDyLClfqiXlS70uIy3Qq/3zB3xSwK/qmogqdjTI8fvlC/i+C5wAkokRzO/4/Zay7e365r9/o4JhNymjbRdF5fvBscYY70xAMv3ju8DUv9NpHldiPnq1b76AX28u/Voz3/lS9Y1RSZLfZ2lAn866suRHsqI2I5pAEnk6gvnQQw9p4sSJXpYgSfL5LOX6G7Rp6t2K7dyiihful3/7euXYO5odC9ZtUjDIoC8AmMzy+zR70Vd6ft7qeLiUpJjtaMHSb/T//W2ZHB/v5UAyefYbtmTJEs2aNcurp2/Gth3ZCij7uJ98dyCqiun/oY1TbpFdt0OSlFHcTb68AkWj/IsXAEwWc6TZi77a5/2r1m5R1fZ6+XzMSAHJ4knA3LZtmyZPnqyxY8d68fR7tTPsV5szRyn3x4ObDji2nGhYkpRxxHEqKLtNOyMhplQAwGCBgE8ff1kl297/e/Xri9fJ52cUE0gWT67BvOeeezRhwgSVl5cf9Pfm5+cmoaImjmOr3U9LVfPR282Ot/3JBQrm5KogEEracx+MwsI8r0tIG/QqMSb1KRj0SzKrJknaFGp6uzSpLlN7JXlbU13Dgf+21DZElJkVUlY7b5cimPizMxW9SowpfUr5b9aMGTPUqVMn9e/fXzNnzjzo76+urjngv0wPxa5FPpum3v2D+zbPeUwdR7ZTzIBFPoWFeaqs3OlpDemCXiXOpD5FIjFJZtUkSZFwVMFQwKi6TO2Vl797Pp+l7p3bHfBxPbu0V2N9WDU76lNQ1d7xHpU4epWYVPbJ57P2O+iX8vmB119/Xe+//75KS0v1hz/8QQsWLNDvfve7VJfRzO6LfOLXXB5xrHJOOLPpAXaURT4AkAZs21Fxhyzlt83c52N8PksDTjkyHtABuC/lI5hPP/10/OuZM2fqgw8+0F133ZXqMprZfZFPzUdvx6+5dCyfrFBm07Fdi3wiXIMJACbzS7rn2n668/H3VdcQbXafz5Ju+/mpCliS7U15QKvA52B+Z9cin2CHI5R9ws/iC3r2dgwAYK5YzFbb7KD+eMtAvfmPDVr00beK2Y569yjQxQO6Kyvklx0jXgLJ5GnALCsrU1lZmZclNLMz7Ff2CWdrZ+T7LcX2dgxA8rC/duLo1b7ZMVuWpAv7H61z+x4tyVHQb8mO2XIIl0DSMYK5h7qwJDkHPAYgOdhfO3H06sCiETu+2CDG5xgDKcOKFQBGYX/txNErAKYiYAIwyj/Kl8b32Mb+0SsApmKKHIBRxvcxZ4cv09ErAKZiBBMAAACuImACMMrbGxbq7Q0LvS4jLdArAKYiYAIwyoqqT7Wi6lOvy0gL9AqAqQiYAAAAcBUBEwAAAK4iYAIAAMBVBEwAAAC4ioAJAAAAVxEwAQAA4CoCJgAAAFxFwAQAAICr2IscgFHYXztx9AqAqRjBBAAAgKsImACMsuf+2tFoVKWl5+mWW27ysCozsRc5AFMxRQ7AKGu3r292e+HCBerR43h99tkqrVu3Vl27HuNRZebZs1cAYAoCpuF8PkttMmyFo7bqIv59HgPS2e6v6V/0uqrZsTmzX9Kgs4eoc+fOmjFjum677S6PqzXHrl4BgGmYIjeYz2cpLxBWxQu/VXj1ImUHY5K012NAutrb63zXsX88dquWL/9YFww5WyUlQzVv3v9q+/ZtXpcMADgARjAN1ibTUcX0SQpXrFO44hm1l5TZe6A2z/j+WH4oU5nH/EQNUf6tgPS05+v83a2rFSo8WgM/+kCvLP5EPzkiR7nVn+uUXj9Rp06dNWfOLF155f/xumwjzF4zV5JU2r3E40oAoDlSicEawzHlnfr9H46t85/RhsfGKVyxTpLkz+ugzK69FHH4dwLS156v888qVmvFyre145uvtOCrbVpZWa+LJ9yvoReXqrq6Si+//KKi0aiHFZtj7fb1XIcJwEgETIPVR/3ydz1N+ReMix9zwvWSmsJl8c/vU63yFIvZXpUIHLa9vs4dWwvWblObrJDeeesNvTzrdb300qt68cXZqq+v04IFb3tYMQDgQAiYhmu0A8o+7ifyZeY2O559bF/ZwRzCJVqEvb3O//ezLRp57umyMtvEX+d5eXkaPnykXnxxmlelAgASQMA0WHzxw/Tfym6oaXbfzg/fUMPKd1nkg7S3r9f5n4b10JCczT94nf/iF+P01FPPeVEqACBBBEyDtcl04gt6pKZp8bb9Lorfv3X+M4p+9U9lBhjFRPra83Vu+YMK5OXH7+d1DgDph4BpsN0XP+y65rL9WZfFr1VjkQ9agj1f56GOXeVrU8jrHADSGO/YBquP+pXV9TQVXHSzMjofp1rlqUMoU/49jnEdJtLZnq/z2NKpki1e5wCQxgiYhquP+pV5ZG/VOoH4H9i9HQPS2e6vaTk/PMbrHADSCwEzDTR9iLp9wGNAOtv1ms4JZv/gGPZu914BgEkImACMwv7aiaNXAEzFIh8AAAC4ioAJwCiz18yN77GN/aNXAEzFFDkAo9RGar0uIW3QKwCmImACMMrlPYd7XULaoFcATMUUOQAAAFxFwARglGmrX9K01S95XUZaoFcATMUUOQCjbK6r8rqEtEGvAJiKEUwAAAC4ioAJAAAAVxEwAQAA4CoCJgAAAFxFwAQAAICrCJgAAABwFQETAAAAruJzMAEYpSi7wOsS0ga9AmAqAiYAo7C/duJ29aq8fKMuu+xidevWQ5LkOLaysrI1YsQonXPOuV6WCKCVIplDiFcAABpRSURBVGACQJqyLEuO40iSMjIy9Mwz0+L3bdpUrptvHie/36eBA8/xqkSkmd1fU8Dh4BpMHJK8UFR5oegBjwEHi/2198/nsyS/TzHLp6c+/h89u/Ilye//weOKizvpuuvGatq0qR5UiXQSCPgkv0+NtrRpe4MabUl+X9Nx4BAxgomDlheKavs7z0qS2g66WjWRgHKDzY/tDPPSwqHJCeZ4XYKx/H6fwrb0xxkfafkXVQocWS1JWlr+gWzbkeX3yYnZ8cf36HGsvvrqS6/KRRrw+X2qrgnr0Rf+pfWbdsaPdynO0/iRp6h9Tkj2bq8pIFGepIDHHntMc+fOlSQNGDBAt99+uxdl4BDkhmLasWiaalcuih8rKBmjqrlT4sesQFB5P7tCNeEfjqoAB1LavcTrEoxlW5bufHyRqrY1SJKi3xwvSaqv26Jw1NYX325Xz6PaKhppCgSWZSkzM9OzemE2n89SbTimOx57T+Fo8xC5ftNO3fHYe5o8YYBygj7ZNtPmODgpH/9evHix3nvvPc2aNUuvvPKKVq5cqbfeeivVZeAQhW2fcnufI8sflCTVrlykDX+8/vtw6Q8qt/c5CttMrQBuCgR9WvTxxni43JsnX1mhqG3Fb69evSq+8AfYk2NZeu71T38QLncJR21Nff1TOZa11/uB/Ul5CigsLNTEiRMVCoUUDAbVvXt3bdy4MdVl4BCFo5YiuUeo4xW/iYdMp7FOUlO47HjFbxTJPULhKG9IODRPfvKcnvzkOa/LME44Jr3x/9Y3Oxbq8S+FevwrfrtyW73qGpuug96wYb2eeeYpjRz585TWifRhy9I/V23a72M+WLVJtng/x8FL+RT5scceG/963bp1mjt3rqZPn57w9+fn5yajrLRSWJjndQmKZfoU6thFjRu/v74r1LGLMgqOVHaWOT8jE3qVDkzqU1iNksyqSZI2hZreLr2qa8uOBtU2RJofDITjXzqxiNb/fbLGfPqksjKCysjI0G233aqSEm8uOTDt52cqL/u0eWudDjTzbTuSLDN+nibUkA5M6ZNnKzG++OILjRkzRrfffru6du2a8PdVV9e06mtBCgvzVFm588APTKJdi3x2D5eS1LjxS1W98ZQxi3xM6FW6MKlPkUhMklk1SVIkHFUwFPCsLsvv0zGd2uhfOyt/cF8wu4OOG/qQLEt68s7B8tnfT3l6US+/e4nxvE9+n9rlZWjbzsZ9PqRdXobkOJ7/PD3vVZpIZZ98Pmu/g36eXCi3bNkyXXPNNbrlllt0ySWXeFECDtGei3wsf1Btzxje7JrMHYumKTcU87JMoMWxHEf/Nvi4/T6mT88i+ZnNRIKCllT6s277fUzpWd0U5DWFQ5DygFleXq4bbrhBjzzyiC688MJUPz0O0+6LfHZdc5l56rD4NZks8gGSw7YdFbfP0sVndd/r/R07ZGtc2cmy+JBsJCgatTXo1KN0co+9bzl6co8CDepzlKL7WAQE7E/K5zGnTJmixsZGPfjgg/FjI0eO1KhRo1JdCg5BOGpJ3y3ykdS0oKfBUWjPYyzyAVznxGyV/uwY9e/VSS8u+Fyr/T75fT5dW9ZL/U4sls92FGvFlxDh4DnRqCaMPEVffL1NL7/7paq31yu/bZYuHdhDxx7VTk6UzTNwaFIeMO+++27dfffdqX5auCgcteTkHCFJinwXJPd2DID7nJitjm0zdGPZyfr9P9+TJJ1+YrGikZi4MAUHy3EkRWPqeVRb3X7FqXLkyJKloE+KRnlF4dB5vxIDaSkS+2GI3NsxAO5rWujoxD88JhohCODwRKNNH0bU9JpyxKw4DhcXygEAAMBVjGACMMoxbbt4XULaoFcATEXABGAU9iJPHL0CYCqmyAEAAOAqAiYAo7AXeeLoFQBTMUUOwChcV5g4egXAVARMAEYZfPQAr0tIG/QKgKmYIgcAAICrCJgAjPLoh0/o0Q+f8LqMtECvAJiKgAkAAABXETABAADgKgImAAAAXEXABAAAgKsImAAAAHAVARMAAACuImACAADAVezkA8BI5eUbddllF6tbtx6SJNuOKSMjU7/85QSdfPKPPa4OALA/BEwARjmp4EfxrzMyMvTMM9Pit+fPf0u/+91v9cILs7wozTi79wpA6lhW038dx9s6TEbARIuRHYwpFPBpR6NPtu3s8xjM4/NZapNhKxy14/trV1SUS2r6GdZF/JKkHTu2Kz+/wLM6TcNe5EDqWJZk+X2yZalyW70Cfp/a5WXILykWjXldnnEImGgRsoMxRT5/X1uXv6PCEXeqJpqhWEPtD44RMs3j81nKDTSq4oUHlHvyIGUfd4YaYgFl+8NqbKjXZSMukZWRo+07dqq6ukoPPPCfXpcMoJWxLEkBv6bOW62FH36jaOy7QYzMgIaffazOPvVI2RFC5u4ImEh7mQFb0bVLteWtv0qSKmc8oOLL71XNJ3///thLD6jjyHu0rc7yslTsRZtMWxUvPKBwxVpteWut/lq+WP6cdhr28VqF/D79YWAH5V8wTr6ufbVoyT9111236tlnX9ARR3T2unTP7dqHfHyfsR5XArRwfr/+8/kPteKr6maH6xqieu71T1VbH9HQ07vKidkeFWgeVpEj7UUVUObRJ8qf216SFK5Yq6///H9V/eaU+GPyTjlPjRF+8U3UGLGVd8p58dsnr1+nkz5fpUjV15Ikf257ZR59oqIKqG/ffurc+Sh9+ulKr8o1Sr9Op6lfp9O8LgNo0Xy+pinxPcPl7mYtXCPGL5sjYCLtRaO26nxtVPzz++Ih02msi9+fXzJW/m59Vf/ddXwwS33EL3+3vsovaRqFO21ng07duiN+f/HP71Odr42iUVsbNqzXpk0bdeyxx3tVrlH6dzpN/QmYQFL5/D69vnjdfh9j244++bJKgQCxahemyNEiRKO27MxcZR/fTzuXzYsf9313bEeDTxLXX5qqMRZQm+P7aes7f9POcG38eDjmaPg118v+bvDZcWzddtuvdfTRXTyq1Cw13/UqN5TjcSVAy2U7jmrrIwd8XE1dRJbFZVi7EDDRImQHY2r89P1m4VKS7IYaVUz/Dxb5GCy+yGf6A7IbavS3zu0kSWPsbfrfK09Uh3OvVfC4M+IryfG9p1ZMlcQ1mEAy+S1Lx3Vpr39+WrHfx3Xr3FYxrsGMYywXaW/PRT6S1Kbv0GbXZFa+9IDaZPKLb6I2mbYqX2pa5CNJlj+gQF5+/P4tb/1V0bVLlRng5wcg9SKRmAb1OVI+375HJzu0yVSn/BwGMXZDwETa23ORT37JWOX0H64jrpoUP8YiH3PtvsjHn9teoaJj5G9TGL8mc/dFPgDgBb8l3XJ5H+0tY2ZlBHTPdf3k5zKsZnjHRtqLRm3VBZoW+TR++7l8R/dWTYNUWNix2TEW+ZipPuJXVre+KhgWUkbn42Qv+5scW/LvdmzXIh8A8IITs3VCl/b6462DNPOdL7X8yyr5/ZZ+1ruzzuvfRUGJ6fE9EDDRIuwKmYGjfqz6yPcD83W+Hx6DeeojfmUe9WPVKRDfem33Y4RLAF5zYrayA5auPL9n0wetW1LIbykaifERRXtBwESLEY3aiu5x1cfejsFMDVGfJPuAxwDAK44jOdFY018VR+LfvvvGX14AAAC4ioAJAAAAVxEwAQAA4CquwQRgFPbWThy9AmAqAiYAo7C3duLoFQBTMUUOwCg14dr4HtvYP3oFwFQETABGeWrF1Pge29g/egXAVEyRAzDKOUef5XUJaYNeATAVAROAUXoVnOB1CWmDXgEwFVPkAIxSUbtZFbWbvS4jLdArAKYiYAIwyvTPZmr6ZzO9LiMt0CsApiJgAgAAwFUETAAAALiKgAkAAABXETABAADgKgImAAAAXEXABAAAgKsImAAAAGnOsryuoDkCJpBEoYCjDnl++f3Wfo8BAHAo/AG/FPBra11Un2/YKgX88gV8ngdOtooEkiQUcBTc/rW+mfpfKr78N6r1t5Hfsn9wLBZzvC7VKOyvnTh6BbRuvqBf85d9o5cXfKHahqgkKeC3NOjUo3TFeT2laFSOR39iPBnBfPXVV3XBBRdoyJAhev75570oAUiqQMCnUF2FNr3wH4rtrNamv92tHGengtu/bnYs198gn4+RzN31KjiBPbYTRK+A1svy+/Tae2v13OufxsOlJEVjjt76YIMembZMjs+7ieqUj2BWVFRo8uTJmjlzpkKhkEaOHKl+/fqpR48eqS4FSJpYzJEvN18ZRV3VWP6lYrXbtXHKrXJiEcmOSZKyepwqW37ZNiOYu9u1t3bHnCKPKzEfvQJaL1vSzIVr9nn/ijXVqtreoKI2GZ78nUl5tF28eLF++tOfql27dsrOztZ5552nefPmpboMIKkcx9HOSEgFl96hjE5N/3hyIg3xcJnb+2y1+dnl2hnmKpU9sb924ugV0DoFAj4t/7LqgMFx7pJ18vm9GcW0HCe1s/N/+ctfVFdXpwkTJkiSZsyYoeXLl+u+++5L6Puvu/9Nbd5an8wSAXjIl7tVkmTXtPe4kuYu/+YNSdK0I8/zuJLvmdorAC1fUfssTbl7yD7vT/nwiW3bsnZb2uQ4TrPbB/LwuNNb9ZRiYWGeKit3el1GWvC6V7sW+Wx64T+kWLTZff6ctir++f2q9Xm/yOfaBxforxPP9rSGdPD1w/9QMBTQX8fTqwPx+ncvXdCnxNGr5nw+S99uqdevn1i838ddcX5Pnd/3KEUisaTUsN/7XX/GAyguLlZlZWX8dmVlpYqKuH4ILcvui3x2hcvsnqcrVNxdkhSr3c4in334avs6fbV9nddlpAV6BbROtu2oU36OOrTJ3OdjfD5LA/scmZRwmYiUB8zTTz9dS5Ys0ZYtW1RfX68333xTZ53FR22gZdl9kY8k5fY+R+3OvU6FwyfGr8nM6nEai3z2Ys6aeZqzhuuyE0GvgNbLL0f/fu1PlJXxw8lonyXdcnkfTz+LMuXP3bFjR02YMEFXXXWVIpGIhg8frpNPPjnVZQBJtfsin7oV7yrrpEHa2eiXZQWaH2ORDwDgEMRitjrkhPTHWwdq3pJ1WvTRRsVsWyf3KNSlA3soO8MvJ2Z7Vp8nf92GDRumYcOGefHUQMrsCpmZJ52rneF9HwMA4FDEYrZ8ki46/Rid36+LgqGAnFhMTszxNFxKbBUJJJXjOKoPH/gYAACHKhqNyec46tAmU3bUVoo/IGivCJgAAABwFQETAAAAriJgAgAAwFUETAAAALiKgAkAAABX8SF8AIxyUffzvS4hbdArAKYiYAIwSre2Xb0uIW3QKwCmYoocgFHYXztx9AqAqQiYAIzC/tqJo1cATMUUOQCjjDq+zOsS0ga9AmAqAiYAo3TMKfK6hLRBrwCYiilyAEb5pGqVPqla5XUZaYFeATAVI5gAjDJ/w98lSb0KTvC4EvPRKwCmYgQTAAAAriJgAgAAwFUETAAAALiKgAkAAABXETABAADgKgImAAAAXEXABAAAgKsImAAAAHAVH7QOwCjsr504egXAVARMAEZhf+3E0SsApmKKHIBR2F87cfQKgKkYwQRgFPbXThy9AmAqAiYAo4w+6UqvS0gb9AqAqQiYAIySG8rxuoS0Qa8AmIprMAEYZUn5Ui0pX+p1GWmBXgEwFQETgFH+Ub5U/yA0JYReATAVARMAAACuImACAADAVQRMAAAAuIqACQAAAFcRMAEAAOAqAiYAAABcRcAEAACAqwiYAAAAcBVbRQIwCvtrJ45eATAVAROAUdhfO3H0CoCpmCIHYBT2104cvQJgKgImAKOwv3bi6BUAUzFFDsAo4/uM9bqEtEGvAJiKEUwAAAC4ioAJwChvb1iotzcs9LqMtECvAJiKgAnAKCuqPtWKqk+9LiMt0CsApiJgAgAAwFUETAAAALiKgAkAAABXETABAADgKgImAAAAXJXygLls2TINHz5cpaWluvrqq/Xtt9+mugQAAAAkUcoD5m233ab7779fs2fP1rBhw3T//fenugQAAAAkUUoDZjgc1s0336yePXtKko4//niVl5ensgQAAAAkmeU4juPFE9u2rXHjxqlXr1668cYbvSgBgKRht8zWq/9Z6nUZxtu84F1JUtHZA70sAwDSQiBZJ547d64eeOCBZse6deumZ555RuFwWBMnTlQ0GtWYMWMO6rzV1TWybU8ysREKC/NUWbnT6zLSAr1KHH06MKvXqbymEkSfEkOfEkevEpPKPvl8lvLzc/d5f9ICZklJiUpKSn5wvLa2VuPGjVO7du30+OOPKxgMJqsEAAAAeMCTRT5dunTRo48+qlAolOqnBwAAQJIlbQRzb1atWqX58+erR48euuSSSyRJRUVFevLJJ1NZBgAAAJIopQHzhBNO0GeffZbKpwQAAECKsZMPAAAAXEXABAAAgKsImAAAAHAVARMAAACuImACAADAVQRMAAAAuIqACQAAAFcRMAEAAOAqAiYAAABcRcAEAACAqwiYAAAAcBUBEwAAAK4iYAIAAMBVBEwAAAC4KuB1AQfL57O8LsFz9CBx9OrAitpn0aeDQK8SQ58SQ58SR68Sk6o+Heh5LMdxnJRUAgAAgFaBKXIAAAC4ioAJAAAAVxEwAQAA4CoCJgAAAFxFwAQAAICrCJgAAABwFQETAAAAriJgAgAAwFUETAAAALiKgAkAAABXETDT2KpVq3TSSSd5XYaxli1bpuHDh6u0tFRXX321vv32W69LMs6rr76qCy64QEOGDNHzzz/vdTnGeuyxx3ThhRfqwgsv1MMPP+x1OcZ76KGHNHHiRK/LMNqCBQtUVlamkpIS3X///V6XY6zZs2fHf/ceeughr8sxTk1NjYYOHapvvvlGkrR48WINGzZMQ4YM0eTJk70tzkFaqqurc0aOHOkcd9xxXpdirEGDBjmffvqp4ziOM2PGDGfs2LEeV2SWTZs2OYMGDXK2bt3q1NbWOsOGDXO++OILr8syzvvvv+9cdtllTmNjoxMOh52rrrrKefPNN70uy1iLFy92+vXr59xxxx1el2KsDRs2OGeeeaZTXl7uhMNhZ9SoUc67777rdVnGqaurc/r27etUV1c7kUjEGT58uPP+++97XZYxPvroI2fo0KHOiSee6Hz99ddOfX29M2DAAGfDhg1OJBJxrr32Wk9fV4xgpqkHH3xQV199tddlGCscDuvmm29Wz549JUnHH3+8ysvLPa7KLIsXL9ZPf/pTtWvXTtnZ2TrvvPM0b948r8syTmFhoSZOnKhQKKRgMKju3btr48aNXpdlpG3btmny5MkaO3as16UY7a233tIFF1yg4uJiBYNBTZ48Wb179/a6LOPEYjHZtq36+npFo1FFo1FlZGR4XZYxXnzxRd17770qKiqSJC1fvlxdunTRUUcdpUAgoGHDhnn6nh7w7JlxyObPn6+Ghgadf/75XpdirFAopNLSUkmSbdt67LHHNHjwYI+rMsvmzZtVWFgYv11UVKTly5d7WJGZjj322PjX69at09y5czV9+nQPKzLXPffcowkTJvCPuQNYv369gsGgxo4dq/Lycg0cOFDjx4/3uizj5Obm6uabb1ZJSYmysrLUt29f9enTx+uyjDFp0qRmt/f2nl5RUZHqsuIImAabO3euHnjggWbHunXrppqaGj3zzDPeFGWgffXpmWeeUTgc1sSJExWNRjVmzBiPKjSTbduyLCt+23GcZrfR3BdffKExY8bo9ttvV9euXb0uxzgzZsxQp06d1L9/f82cOdPrcowWi8W0dOlSTZ06VdnZ2Ro3bpxmzZqlsrIyr0szyurVq/Xyyy/rnXfeUV5enm699VZNmTJFo0eP9ro0I5n2nk7ANFhJSYlKSkqaHZsxY4b+8pe/6IorrogfKy0t1fPPP6/c3NxUl2iEvfVJkmprazVu3Di1a9dOjz/+uILBoAfVmau4uFhLly6N366srIxPtaC5ZcuW6aabbtJdd92lCy+80OtyjPT666+rsrJSpaWl2r59u+rq6vS73/1Od911l9elGaegoED9+/dXhw4dJEmDBw/W8uXLCZh7eO+999S/f3/l5+dLksrKyjRt2jQC5j4UFxersrIyftvr93SuwUwzI0aM0Ntvv63Zs2dr9uzZkppW2bXWcLk/t912m7p06aJHH31UoVDI63KMc/rpp2vJkiXasmWL6uvr9eabb+qss87yuizjlJeX64YbbtAjjzxCuNyPp59+Wq+99ppmz56tm266SWeffTbhch8GDRqk9957Tzt27FAsFtOiRYt04oknel2WcXr27KnFixerrq5OjuNowYIF6tWrl9dlGat3795au3at1q9fr1gsptdee83T93RGMNEirVq1SvPnz1ePHj10ySWXSGq6HuXJJ5/0uDJzdOzYURMmTNBVV12lSCSi4cOH6+STT/a6LONMmTJFjY2NevDBB+PHRo4cqVGjRnlYFdJZ7969NXr0aF1++eWKRCI644wzdOmll3pdlnHOPPNMrVq1SmVlZQoGg+rVq5euv/56r8syVkZGhh588EH98pe/VGNjowYMGODpWg3LcRzHs2cHAABAi8MUOQAAAFxFwAQAAICrCJgAAABwFQETAAAAriJgAgAAwFUETADwgOM4uuOOOzRlyhSvSwEA1xEwASDF1qxZo6uvvlpvvPGG16UAQFIQMAEgSWbNmqXBgwertrZWdXV1Kikp0SuvvKLnn39eI0aM8PRDkAEgmfigdQBIoltuuUV5eXkKh8Py+/2677774vdNnDhRxx57rK677joPKwQA97FVJAAk0W9/+1uVlpYqMzNTM2fO9LocAEgJpsgBIImqq6vV2NioHTt2aPPmzV6XAwApwQgmACRJJBLRr371K918882ybVsTJkzQ9OnTFQwGvS4NAJKKEUwASJLf//73Kigo0IgRI3TZZZepffv2mjx5stdlAUDSscgHAAAArmIEEwAAAK4iYAIAAMBVBEwAAAC4ioAJAAAAVxEwAQAA4CoCJgAAAFxFwAQAAICr/n8ztZzwr2E4sAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 792x612 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "# Use axes level function in sns to draw the random plot\n",
    "\n",
    "# Co-ordinates for lines\n",
    "margin_X = 2 * np.ones(12)\n",
    "margin_Y = np.linspace(-2, 12, num=12)\n",
    "\n",
    "gutter1_X = np.ones(12)\n",
    "gutter1_Y = np.linspace(-2, 12, num=12)\n",
    "\n",
    "gutter2_X = 3 * np.ones(12)\n",
    "gutter2_Y = np.linspace(-2, 12, num=12)\n",
    "\n",
    "# Prepare the plot\n",
    "fig, ax = plt.subplots(figsize = (11, 8.5))\n",
    "sns.scatterplot(x='x1', y='x2', hue='y', style='y', data=df, s=100)\n",
    "ax.axhline(y=0, linewidth=1)\n",
    "ax.axvline(x=0, linewidth=1)\n",
    "\n",
    "plt.plot(margin_X, margin_Y, color='r')\n",
    "plt.plot(gutter1_X, gutter1_Y, 'g-.')\n",
    "plt.plot(gutter2_X, gutter2_Y, 'g-.')\n",
    "\n",
    "plt.text(x=1, y=3, s=\"A\")\n",
    "plt.text(x=1, y=1, s=\"B\")\n",
    "plt.text(x=3, y=2, s=\"D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2  y\n",
       "0   -3   2  1\n",
       "1   -1   0  1\n",
       "2   -4   3  1\n",
       "3   -2   1  1\n",
       "4   -5   4  1\n",
       "5    1   1  1\n",
       "6    1   3  1\n",
       "7   10   0  0\n",
       "8    4   5  0\n",
       "9    5   4  0\n",
       "10   9   1  0\n",
       "11   7   2  0\n",
       "12   8   6  0\n",
       "13   3   2  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 2.],\n",
       "       [1., 1.],\n",
       "       [1., 3.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X,y)\n",
    "model.support_vectors_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  5,  6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5001472,  0.2500736,  0.2500736]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dual_coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconcile the above values with manually calculated $\\alpha$ values above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0002944,  0.       ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconcile the above values with the values calculated for $\\vec{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00049067])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconcile the above with values calculated for b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "1. $\\vec{w}$ was calculated as $\\begin{bmatrix} -1 & 0 \\end{bmatrix}$\n",
    "Values from python program array([[-0.99968,  0.     ]])\n",
    "\n",
    "2. Value of the intercept derived is 1.99946. Value derived via manual calculation is 2.\n",
    "\n",
    "3. Values of support vectors derived are : \n",
    "$$\\alpha_A = 1/4$$\n",
    "$$\\alpha_B = 1/4$$\n",
    "$$\\alpha_D = 1/2$$\n",
    "\n",
    "Values from python program, derived via dual_coef_ array([[-0.49984,  0.24992,  0.24992]]), matches, ordering by class of the support vectors probably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to ponder upon:\n",
    "\n",
    "* 1. What happens if the support vectors move far out horizontally? What will happen to supportiveness of the points? What will happen to weights?\n",
    "* 2. What happens if support vectors move vertically? What will happen to the supportiveness of points? What will happen to weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering Issues\n",
    "If there are rendering issues with maths equations above, will be good to check \n",
    "nbconvert version\n",
    "https://github.com/jupyter/notebook/issues/2865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nbconvert\n",
    "# print(nbconvert.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for images used in the diagram is available in the repo in the img subfolder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
